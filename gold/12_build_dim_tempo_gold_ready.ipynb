{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a30f5f70",
   "metadata": {},
   "source": [
    "# ðŸ—“ï¸ 12 â€” DIM_TEMPO (Gold)\n",
    "\n",
    "- LÃª `silver/2018_anonimizado.xlsx` e `silver/2019_anonimizado.xlsx`\n",
    "- ConstrÃ³i dimensÃ£o de datas usando `DATA`, `DATA_DO_ULTIMO_ATO`, `DATA_DE_ENTRADA_FASE_ATUAL`\n",
    "- Exporta em `gold/output/dim_tempo.csv`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb8fbb2",
   "metadata": {},
   "source": [
    "## 0) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f57624f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f230a39",
   "metadata": {},
   "source": [
    "## 1) Paths robustos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d024eb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# ======================================================\n",
    "# Paths robustos (funciona no VS Code / Jupyter / OneDrive)\n",
    "# - encontra a raiz do projeto procurando a pasta 'silver'\n",
    "# ======================================================\n",
    "CWD = Path().resolve()\n",
    "\n",
    "def find_project_root(start: Path) -> Path:\n",
    "    p = start\n",
    "    for _ in range(12):\n",
    "        if (p / \"silver\").exists():\n",
    "            return p\n",
    "        if p.parent == p:\n",
    "            break\n",
    "        p = p.parent\n",
    "    raise FileNotFoundError(\"NÃ£o encontrei a pasta 'silver' subindo a Ã¡rvore. Rode o notebook dentro do repo.\")\n",
    "\n",
    "PROJECT_ROOT = find_project_root(CWD)\n",
    "SILVER_DIR = PROJECT_ROOT / \"silver\"\n",
    "GOLD_DIR = PROJECT_ROOT / \"gold\"\n",
    "OUT_DIR = GOLD_DIR / \"output\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"ðŸ“Œ CWD:\", CWD)\n",
    "print(\"ðŸ“Œ PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"ðŸ“Œ SILVER_DIR:\", SILVER_DIR)\n",
    "print(\"ðŸ“Œ OUT_DIR:\", OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fde6ed",
   "metadata": {},
   "source": [
    "## 2) Ler Silver (2018 + 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f51aeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "INPUT_FILES = [\n",
    "    SILVER_DIR / \"2018_anonimizado.xlsx\",\n",
    "    SILVER_DIR / \"2019_anonimizado.xlsx\",\n",
    "]\n",
    "\n",
    "print(\"ðŸ“¥ INPUT_FILES:\")\n",
    "for f in INPUT_FILES:\n",
    "    print(\" -\", f, \"| existe?\", f.exists())\n",
    "\n",
    "dfs = []\n",
    "for f in INPUT_FILES:\n",
    "    if not f.exists():\n",
    "        raise FileNotFoundError(f\"Arquivo nÃ£o encontrado: {f}\")\n",
    "    tmp = pd.read_excel(f, dtype=str)\n",
    "    tmp[\"fonte_arquivo\"] = f.name\n",
    "    dfs.append(tmp)\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "print(\"âœ… Linhas/Colunas consolidadas:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495c7f4a",
   "metadata": {},
   "source": [
    "## 3) Construir DIM_TEMPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20287f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cols = [c for c in [\"DATA\", \"DATA_DO_ULTIMO_ATO\", \"DATA_DE_ENTRADA_FASE_ATUAL\"] if c in df.columns]\n",
    "if not date_cols:\n",
    "    raise KeyError(\"NÃ£o encontrei colunas de data (DATA/DATA_DO_ULTIMO_ATO/DATA_DE_ENTRADA_FASE_ATUAL).\")\n",
    "\n",
    "all_dates = []\n",
    "for c in date_cols:\n",
    "    d = pd.to_datetime(df[c], errors=\"coerce\", dayfirst=True).dt.normalize()\n",
    "    all_dates.append(d)\n",
    "\n",
    "dates = pd.concat(all_dates, axis=0).dropna().drop_duplicates().sort_values()\n",
    "\n",
    "dim_tempo = pd.DataFrame({\"data\": dates})\n",
    "dim_tempo[\"id_data\"] = dim_tempo[\"data\"].dt.strftime(\"%Y%m%d\").astype(int)\n",
    "dim_tempo[\"ano\"] = dim_tempo[\"data\"].dt.year\n",
    "dim_tempo[\"mes\"] = dim_tempo[\"data\"].dt.month\n",
    "dim_tempo[\"dia\"] = dim_tempo[\"data\"].dt.day\n",
    "dim_tempo[\"trimestre\"] = dim_tempo[\"data\"].dt.quarter\n",
    "dim_tempo[\"semana_ano\"] = dim_tempo[\"data\"].dt.isocalendar().week.astype(int)\n",
    "dim_tempo[\"dia_semana\"] = dim_tempo[\"data\"].dt.dayofweek\n",
    "dim_tempo[\"nome_dia\"] = dim_tempo[\"data\"].dt.day_name()\n",
    "dim_tempo[\"nome_mes\"] = dim_tempo[\"data\"].dt.month_name()\n",
    "\n",
    "print(\"âœ… DIM_TEMPO pronta:\", dim_tempo.shape)\n",
    "dim_tempo.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c0ba2b",
   "metadata": {},
   "source": [
    "## 4) Exportar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0aa2031",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = OUT_DIR / \"dim_tempo.csv\"\n",
    "dim_tempo.to_csv(out_file, index=False, encoding=\"utf-8\")\n",
    "print(\"âœ… Salvo em:\", out_file)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
