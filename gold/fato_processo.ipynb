{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57bb6b71",
   "metadata": {},
   "source": [
    "# â­ 20 â€” FATO_PROCESSO_REGULATORIO (Gold)\n",
    "\n",
    "GrÃ£o: **1 linha = 1 processo**\n",
    "\n",
    "- LÃª `silver/2018_anonimizado.xlsx` e `silver/2019_anonimizado.xlsx`\n",
    "- Prepara IDs e chaves de tempo\n",
    "- Cria mÃ©tricas e flags para BI\n",
    "- Exporta em `gold/output/fato_processo_regulatorio.csv`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3c12e6",
   "metadata": {},
   "source": [
    "## 0) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe7c9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1251e7",
   "metadata": {},
   "source": [
    "## 1) Paths robustos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41c81d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# ======================================================\n",
    "# Paths robustos (funciona no VS Code / Jupyter / OneDrive)\n",
    "# - encontra a raiz do projeto procurando a pasta 'silver'\n",
    "# ======================================================\n",
    "CWD = Path().resolve()\n",
    "\n",
    "def find_project_root(start: Path) -> Path:\n",
    "    p = start\n",
    "    for _ in range(12):\n",
    "        if (p / \"silver\").exists():\n",
    "            return p\n",
    "        if p.parent == p:\n",
    "            break\n",
    "        p = p.parent\n",
    "    raise FileNotFoundError(\"NÃ£o encontrei a pasta 'silver' subindo a Ã¡rvore. Rode o notebook dentro do repo.\")\n",
    "\n",
    "PROJECT_ROOT = find_project_root(CWD)\n",
    "SILVER_DIR = PROJECT_ROOT / \"silver\"\n",
    "GOLD_DIR = PROJECT_ROOT / \"gold\"\n",
    "OUT_DIR = GOLD_DIR / \"output\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"ðŸ“Œ CWD:\", CWD)\n",
    "print(\"ðŸ“Œ PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"ðŸ“Œ SILVER_DIR:\", SILVER_DIR)\n",
    "print(\"ðŸ“Œ OUT_DIR:\", OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e304600c",
   "metadata": {},
   "source": [
    "## 2) Ler Silver (2018 + 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d05bbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "INPUT_FILES = [\n",
    "    SILVER_DIR / \"2018_anonimizado.xlsx\",\n",
    "    SILVER_DIR / \"2019_anonimizado.xlsx\",\n",
    "]\n",
    "\n",
    "print(\"ðŸ“¥ INPUT_FILES:\")\n",
    "for f in INPUT_FILES:\n",
    "    print(\" -\", f, \"| existe?\", f.exists())\n",
    "\n",
    "dfs = []\n",
    "for f in INPUT_FILES:\n",
    "    if not f.exists():\n",
    "        raise FileNotFoundError(f\"Arquivo nÃ£o encontrado: {f}\")\n",
    "    tmp = pd.read_excel(f, dtype=str)\n",
    "    tmp[\"fonte_arquivo\"] = f.name\n",
    "    dfs.append(tmp)\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "print(\"âœ… Linhas/Colunas consolidadas:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b17dd54",
   "metadata": {},
   "source": [
    "## 3) FunÃ§Ãµes auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca054404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def norm_missing(s: pd.Series) -> pd.Series:\n",
    "    x = s.astype(str).str.strip()\n",
    "    return x.replace({\"\": np.nan, \"nan\": np.nan, \"NAN\": np.nan, \"None\": np.nan, \"NONE\": np.nan})\n",
    "\n",
    "def dedup_most_complete(df_in: pd.DataFrame, key: str) -> pd.DataFrame:\n",
    "    score = df_in.notna().sum(axis=1)\n",
    "    return (df_in.assign(_score=score)\n",
    "              .sort_values([key, \"_score\"], ascending=[True, False])\n",
    "              .drop_duplicates(subset=[key], keep=\"first\")\n",
    "              .drop(columns=[\"_score\"]))\n",
    "\n",
    "def pick_first_existing(candidates, df_):\n",
    "    return next((c for c in candidates if c in df_.columns), None)\n",
    "\n",
    "\n",
    "def to_numeric(s: pd.Series):\n",
    "    return pd.to_numeric(s, errors='coerce')\n",
    "\n",
    "def mk_date_key(s: pd.Series):\n",
    "    d = pd.to_datetime(s, errors='coerce', dayfirst=True).dt.normalize()\n",
    "    return d.dt.strftime('%Y%m%d').astype('Int64'), d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b804a4",
   "metadata": {},
   "source": [
    "## 4) Construir FATO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110ca0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact = df.copy()\n",
    "\n",
    "fact[\"id_processo\"] = norm_missing(fact[\"NO_DO_PROCESSO\"]) if \"NO_DO_PROCESSO\" in fact.columns else pd.Series(range(1, len(fact)+1), dtype=\"Int64\")\n",
    "fact[\"id_curso\"] = norm_missing(fact[\"CODIGO_DO_CURSO\"]) if \"CODIGO_DO_CURSO\" in fact.columns else pd.NA\n",
    "\n",
    "if \"IES_ID_FAKE\" in fact.columns:\n",
    "    fact[\"id_ies\"] = norm_missing(fact[\"IES_ID_FAKE\"])\n",
    "elif \"CODIGO_DA_IES\" in fact.columns:\n",
    "    fact[\"id_ies\"] = norm_missing(fact[\"CODIGO_DA_IES\"])\n",
    "else:\n",
    "    fact[\"id_ies\"] = pd.NA\n",
    "\n",
    "uf_proc = norm_missing(fact[\"UF_PROCESSO\"]) if \"UF_PROCESSO\" in fact.columns else pd.Series([pd.NA]*len(fact))\n",
    "uf_cad  = norm_missing(fact[\"UF_CADASTRO\"]) if \"UF_CADASTRO\" in fact.columns else pd.Series([pd.NA]*len(fact))\n",
    "mun_proc = norm_missing(fact[\"MUNICIPIO_PROCESSO\"]) if \"MUNICIPIO_PROCESSO\" in fact.columns else pd.Series([pd.NA]*len(fact))\n",
    "mun_cad  = norm_missing(fact[\"MUNICIPIO_CADASTRO\"]) if \"MUNICIPIO_CADASTRO\" in fact.columns else pd.Series([pd.NA]*len(fact))\n",
    "\n",
    "fact[\"uf\"] = uf_proc.fillna(uf_cad).str.upper()\n",
    "fact[\"municipio\"] = mun_proc.fillna(mun_cad).str.upper().replace({\"\": np.nan}).fillna(\"NÃƒO INFORMADO\")\n",
    "\n",
    "# Modalidade norm\n",
    "if \"MODALIDADE\" in fact.columns:\n",
    "    m = norm_missing(fact[\"MODALIDADE\"]).str.upper()\n",
    "    fact[\"modalidade_norm\"] = m.replace({\"SEMI-PRESENCIAL\":\"SEMIPRESENCIAL\"}).fillna(\"NÃƒO INFORMADO\")\n",
    "else:\n",
    "    fact[\"modalidade_norm\"] = \"NÃƒO INFORMADO\"\n",
    "\n",
    "# Datas -> chaves\n",
    "fact[\"dt_protocolo_key\"], dt_prot = mk_date_key(fact[\"DATA\"]) if \"DATA\" in fact.columns else (pd.Series([pd.NA]*len(fact), dtype=\"Int64\"), pd.to_datetime(pd.Series([pd.NA]*len(fact)), errors=\"coerce\"))\n",
    "fact[\"dt_ultimo_ato_key\"], dt_ult = mk_date_key(fact[\"DATA_DO_ULTIMO_ATO\"]) if \"DATA_DO_ULTIMO_ATO\" in fact.columns else (pd.Series([pd.NA]*len(fact), dtype=\"Int64\"), pd.to_datetime(pd.Series([pd.NA]*len(fact)), errors=\"coerce\"))\n",
    "fact[\"dt_entrada_fase_key\"], dt_fase = mk_date_key(fact[\"DATA_DE_ENTRADA_FASE_ATUAL\"]) if \"DATA_DE_ENTRADA_FASE_ATUAL\" in fact.columns else (pd.Series([pd.NA]*len(fact), dtype=\"Int64\"), pd.to_datetime(pd.Series([pd.NA]*len(fact)), errors=\"coerce\"))\n",
    "\n",
    "# tempo_tramitacao_dias\n",
    "if \"tempo_tramitacao_dias\" in fact.columns:\n",
    "    fact[\"tempo_tramitacao_dias\"] = to_numeric(fact[\"tempo_tramitacao_dias\"])\n",
    "else:\n",
    "    fact[\"tempo_tramitacao_dias\"] = (dt_fase - dt_prot).dt.days if (\"DATA\" in fact.columns and \"DATA_DE_ENTRADA_FASE_ATUAL\" in fact.columns) else np.nan\n",
    "fact.loc[fact[\"tempo_tramitacao_dias\"] < 0, \"tempo_tramitacao_dias\"] = np.nan\n",
    "\n",
    "# vagas\n",
    "if \"VAGAS_SOLICITADAS_PROCESSO\" in fact.columns:\n",
    "    fact[\"VAGAS_SOLICITADAS_PROCESSO\"] = to_numeric(fact[\"VAGAS_SOLICITADAS_PROCESSO\"])\n",
    "if \"VAGAS_AUTORIZADAS_CADASTRO\" in fact.columns:\n",
    "    fact[\"VAGAS_AUTORIZADAS_CADASTRO\"] = to_numeric(fact[\"VAGAS_AUTORIZADAS_CADASTRO\"])\n",
    "\n",
    "if \"dif_vagas_processo_cadastro\" in fact.columns:\n",
    "    fact[\"dif_vagas_processo_cadastro\"] = to_numeric(fact[\"dif_vagas_processo_cadastro\"])\n",
    "else:\n",
    "    if {\"VAGAS_SOLICITADAS_PROCESSO\",\"VAGAS_AUTORIZADAS_CADASTRO\"}.issubset(fact.columns):\n",
    "        fact[\"dif_vagas_processo_cadastro\"] = fact[\"VAGAS_SOLICITADAS_PROCESSO\"].fillna(0) - fact[\"VAGAS_AUTORIZADAS_CADASTRO\"].fillna(0)\n",
    "    else:\n",
    "        fact[\"dif_vagas_processo_cadastro\"] = np.nan\n",
    "\n",
    "if \"tem_divergencia_vagas\" in fact.columns:\n",
    "    fact[\"tem_divergencia_vagas\"] = to_numeric(fact[\"tem_divergencia_vagas\"]).fillna(0).astype(int)\n",
    "else:\n",
    "    fact[\"tem_divergencia_vagas\"] = fact[\"dif_vagas_processo_cadastro\"].fillna(0).ne(0).astype(int)\n",
    "\n",
    "# flags\n",
    "if \"IS_SEDE_EAD\" in fact.columns:\n",
    "    v = norm_missing(fact[\"IS_SEDE_EAD\"]).str.upper()\n",
    "    fact[\"is_sede_ead_flag\"] = v.isin([\"SIM\",\"S\",\"TRUE\",\"1\",\"EAD\"]).astype(int)\n",
    "else:\n",
    "    fact[\"is_sede_ead_flag\"] = 0\n",
    "\n",
    "if \"ENDERECO_DIVERGENTE\" in fact.columns:\n",
    "    v = norm_missing(fact[\"ENDERECO_DIVERGENTE\"]).str.upper()\n",
    "    fact[\"endereco_divergente_flag\"] = v.isin([\"SIM\",\"S\",\"TRUE\",\"1\"]).astype(int)\n",
    "else:\n",
    "    fact[\"endereco_divergente_flag\"] = 0\n",
    "\n",
    "# CINE geral\n",
    "fact[\"cine_area_geral\"] = norm_missing(fact[\"AREA_GERAL_CINE\"]).fillna(\"NÃ£o informado\") if \"AREA_GERAL_CINE\" in fact.columns else \"NÃ£o informado\"\n",
    "\n",
    "# SeleÃ§Ã£o final\n",
    "keep = [\n",
    "    \"id_processo\",\"id_ies\",\"id_curso\",\n",
    "    \"uf\",\"municipio\",\n",
    "    \"modalidade_norm\",\n",
    "    \"ANO_DO_PROTOCOLO\" if \"ANO_DO_PROTOCOLO\" in fact.columns else None,\n",
    "    \"dt_protocolo_key\",\"dt_ultimo_ato_key\",\"dt_entrada_fase_key\",\n",
    "    \"tempo_tramitacao_dias\",\n",
    "    \"VAGAS_SOLICITADAS_PROCESSO\" if \"VAGAS_SOLICITADAS_PROCESSO\" in fact.columns else None,\n",
    "    \"VAGAS_AUTORIZADAS_CADASTRO\" if \"VAGAS_AUTORIZADAS_CADASTRO\" in fact.columns else None,\n",
    "    \"dif_vagas_processo_cadastro\",\"tem_divergencia_vagas\",\n",
    "    \"is_sede_ead_flag\",\"endereco_divergente_flag\",\n",
    "    \"cine_area_geral\",\n",
    "    \"ATO\" if \"ATO\" in fact.columns else None,\n",
    "    \"CATEGORIA_ATO\" if \"CATEGORIA_ATO\" in fact.columns else None,\n",
    "    \"ORGAO\" if \"ORGAO\" in fact.columns else None,\n",
    "    \"FASE_ATUAL\" if \"FASE_ATUAL\" in fact.columns else None,\n",
    "    \"SITUACAO_DO_PROCESSO\" if \"SITUACAO_DO_PROCESSO\" in fact.columns else None,\n",
    "]\n",
    "keep = [c for c in keep if c is not None and c in fact.columns]\n",
    "fato = fact[keep].copy()\n",
    "\n",
    "print(\"âœ… FATO pronto:\", fato.shape)\n",
    "fato.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ec17fb",
   "metadata": {},
   "source": [
    "## 5) Exportar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ba0b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = OUT_DIR / \"fato_processo_regulatorio.csv\"\n",
    "fato.to_csv(out_file, index=False, encoding=\"utf-8\")\n",
    "print(\"âœ… Salvo em:\", out_file)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
